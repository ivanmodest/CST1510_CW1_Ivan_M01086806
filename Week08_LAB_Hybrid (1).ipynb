{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Week 8: Data Pipeline & CRUD (SQL)\n",
    "## CST1510 â€” Multi-Domain Intelligence Platform\n",
    "\n",
    "**Building Your Database Layer**\n",
    "\n",
    "<hr style=\"border:2px solid #0EA5E9\">\n",
    "\n",
    "### What You'll Build This Week\n",
    "\n",
    "This week, you're transitioning from **file-based storage** (`users.txt`) to a **professional database system** (SQLite). By the end of this lab, you will have:\n",
    "\n",
    "1.  **Migrated** your Week 7 users from `users.txt` â†’ SQLite database\n",
    "2.  **Created** database tables for all three domains (cyber_incidents, datasets_metadata, it_tickets)\n",
    "3.  **Loaded** CSV data using pandas\n",
    "4.  **Implemented** CRUD operations (Create, Read, Update, Delete) using Python functions\n",
    "5.  **Secured** your queries against SQL injection attacks\n",
    "6.  **Tested** your database with real-world queries\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By completing this lab, you will:\n",
    "\n",
    "- Understand **why databases are better** than text files for data storage\n",
    "- Learn how to **connect to SQLite** using Python's built-in `sqlite3` module\n",
    "- Write **SQL CREATE TABLE** statements to define your data structure\n",
    "- Implement **CRUD operations** using Python functions\n",
    "- Use **parameterized queries** to prevent SQL injection\n",
    "- Load **CSV files** efficiently using pandas\n",
    "- Query your database to extract **meaningful insights**\n",
    "\n",
    "###  Beginner Tip\n",
    "\n",
    "Think of a database like a **super-powered Excel file** that:\n",
    "- Lives on disk (persists data)\n",
    "- Lets you search, add, update, and delete data **without reading the whole file**\n",
    "- Can link related data together (users â†’ incidents)\n",
    "- Protects against data corruption\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part0",
   "metadata": {},
   "source": [
    "## Part 0: Prerequisites & Setup\n",
    "\n",
    "### Step 0.1: Check Your Project Structure\n",
    "\n",
    "Before starting, make sure your project follows this structure:\n",
    "\n",
    "```\n",
    "CW2_M0123456_CST1510/\n",
    "â”‚\n",
    "â”œâ”€ app/\n",
    "â”‚  â””â”€ data/              # Your database functions will go here\n",
    "â”‚\n",
    "â”œâ”€ DATA/                 # IMPORTANT: Uppercase DATA folder\n",
    "â”‚  â”œâ”€ users.txt          # From Week 7\n",
    "â”‚  â”œâ”€ cyber_incidents.csv\n",
    "â”‚  â”œâ”€ datasets_metadata.csv\n",
    "â”‚  â”œâ”€ it_tickets.csv\n",
    "â”‚  â””â”€ intelligence_platform.db  # Will be created by your code\n",
    "â”‚\n",
    "â””â”€ requirements.txt\n",
    "```\n",
    "\n",
    "### Step 0.2: Install Required Libraries\n",
    "\n",
    "We'll use:\n",
    "- `sqlite3` â†’ **Built-in** to Python (no install needed!)\n",
    "- `pandas` â†’ For easy CSV loading\n",
    "- `bcrypt` â†’ For password hashing (from Week 7)\n",
    "\n",
    "Run this cell to install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pandas bcrypt # in your project environment you just use pip install pandas bcrypt without the !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "### Step 0.3: Import Modules and Define Constants\n",
    "\n",
    "Let's import everything we need and set up our paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1fb2813-1f55-43e4-91cc-1dad83b257b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\spark\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\spark\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\spark\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\spark\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\spark\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\spark\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "imports_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Imports successful!\n",
      " DATA folder: C:\\Users\\Spark\\DATA\n",
      " Database will be created at: C:\\Users\\Spark\\DATA\\intelligence_platform.db\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import bcrypt\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = Path(\"DATA\")\n",
    "DB_PATH = DATA_DIR / \"intelligence_platform.db\"\n",
    "\n",
    "# Create DATA folder if it doesn't exist\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\" Imports successful!\")\n",
    "print(f\" DATA folder: {DATA_DIR.resolve()}\")\n",
    "print(f\" Database will be created at: {DB_PATH.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "file_organization",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## IMPORTANT: From One File to Many Files\n",
    "\n",
    "### Understanding the Transition\n",
    "\n",
    "**In Week 7**, you created a single file (`auth.py`) with all your authentication functions. This works great for small projects!\n",
    "\n",
    "**In Week 8+**, your project is growing, so we're organizing code into **multiple files** for better organization. This is how professional developers work!\n",
    "\n",
    "### Why Multiple Files?\n",
    "\n",
    "| Single File (Week 7) | Multiple Files (Week 8+) |\n",
    "|---------------------|-------------------------|\n",
    "|  Simple to start | Better organization |\n",
    "|  Easy to find everything |  Easier to maintain |\n",
    "|  Gets messy as code grows |  Team-friendly |\n",
    "|  Hard to reuse code |  Reusable modules |\n",
    "|  Difficult to test |  Easy to test |\n",
    "\n",
    "### Beginner Analogy\n",
    "\n",
    "Think of it like organizing your closet:\n",
    "- **Week 7**: Everything in one drawer (works when you don't have much)\n",
    "- **Week 8+**: Separate drawers for shirts, pants, socks (much better as your wardrobe grows!)\n",
    "\n",
    "---\n",
    "\n",
    "##  Your Week 8 File Organization\n",
    "\n",
    "### Complete Project Structure\n",
    "\n",
    "```\n",
    "CW2_M0123456_CST1510/\n",
    "â”‚\n",
    "â”œâ”€ app/\n",
    "â”‚  â”œâ”€ data/                    # Database layer (Model in MVC)\n",
    "â”‚  â”‚  â”œâ”€ __init__.py           # Makes this a Python package\n",
    "â”‚  â”‚  â”œâ”€ db.py                 # Database connection functions\n",
    "â”‚  â”‚  â”œâ”€ schema.py             # CREATE TABLE statements\n",
    "â”‚  â”‚  â”œâ”€ users.py              # User CRUD functions\n",
    "â”‚  â”‚  â”œâ”€ incidents.py          # Incident CRUD functions\n",
    "â”‚  â”‚  â”œâ”€ datasets.py           # Dataset CRUD functions\n",
    "â”‚  â”‚  â””â”€ tickets.py            # Ticket CRUD functions\n",
    "â”‚  â”‚\n",
    "â”‚  â””â”€ services/                # Business logic layer\n",
    "â”‚     â”œâ”€ __init__.py\n",
    "â”‚     â””â”€ user_service.py       # User migration & auth functions\n",
    "â”‚\n",
    "â”œâ”€ DATA/                       # Data files (UPPERCASE)\n",
    "â”‚  â”œâ”€ users.txt                # From Week 7\n",
    "â”‚  â”œâ”€ cyber_incidents.csv\n",
    "â”‚  â”œâ”€ datasets_metadata.csv\n",
    "â”‚  â”œâ”€ it_tickets.csv\n",
    "â”‚  â””â”€ intelligence_platform.db # Created by your code\n",
    "â”‚\n",
    "â”œâ”€ docs/\n",
    "â”‚  â””â”€ README.md                # Project documentation\n",
    "â”‚\n",
    "â”œâ”€ main.py                     # Demo script (entry point)\n",
    "â”œâ”€ requirements.txt            # Python dependencies\n",
    "â””â”€ .gitignore                  # Git ignore file\n",
    "```\n",
    "\n",
    "### What Goes in Each File?\n",
    "\n",
    "#### `app/data/db.py` â€” Database Connection\n",
    "**Purpose**: Connect to and close the database\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "DB_PATH = Path(\"DATA\") / \"intelligence_platform.db\"\n",
    "\n",
    "def connect_database(db_path=DB_PATH):\n",
    "    \"\"\"Connect to SQLite database.\"\"\"\n",
    "    return sqlite3.connect(str(db_path))\n",
    "```\n",
    "\n",
    "####  `app/data/schema.py` â€” Table Definitions\n",
    "**Purpose**: All CREATE TABLE statements\n",
    "\n",
    "```python\n",
    "def create_users_table(conn):\n",
    "    \"\"\"Create users table.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS users (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            username TEXT NOT NULL UNIQUE,\n",
    "            password_hash TEXT NOT NULL,\n",
    "            role TEXT DEFAULT 'user'\n",
    "        )\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "\n",
    "def create_all_tables(conn):\n",
    "    \"\"\"Create all tables.\"\"\"\n",
    "    create_users_table(conn)\n",
    "    create_cyber_incidents_table(conn)\n",
    "    create_datasets_metadata_table(conn)\n",
    "    create_it_tickets_table(conn)\n",
    "```\n",
    "\n",
    "#### `app/data/users.py` â€” User CRUD Operations\n",
    "**Purpose**: All functions for managing users\n",
    "\n",
    "```python\n",
    "from app.data.db import connect_database\n",
    "\n",
    "def get_user_by_username(username):\n",
    "    \"\"\"Retrieve user by username.\"\"\"\n",
    "    conn = connect_database()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\n",
    "        \"SELECT * FROM users WHERE username = ?\",\n",
    "        (username,)\n",
    "    )\n",
    "    user = cursor.fetchone()\n",
    "    conn.close()\n",
    "    return user\n",
    "\n",
    "def insert_user(username, password_hash, role='user'):\n",
    "    \"\"\"Insert new user.\"\"\"\n",
    "    conn = connect_database()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\n",
    "        \"INSERT INTO users (username, password_hash, role) VALUES (?, ?, ?)\",\n",
    "        (username, password_hash, role)\n",
    "    )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "```\n",
    "\n",
    "####  `app/data/incidents.py` â€” Incident CRUD Operations\n",
    "**Purpose**: All functions for managing cyber incidents\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from app.data.db import connect_database\n",
    "\n",
    "def insert_incident(date, incident_type, severity, status, description, reported_by=None):\n",
    "    \"\"\"Insert new incident.\"\"\"\n",
    "    conn = connect_database()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO cyber_incidents \n",
    "        (date, incident_type, severity, status, description, reported_by)\n",
    "        VALUES (?, ?, ?, ?, ?, ?)\n",
    "    \"\"\", (date, incident_type, severity, status, description, reported_by))\n",
    "    conn.commit()\n",
    "    incident_id = cursor.lastrowid\n",
    "    conn.close()\n",
    "    return incident_id\n",
    "\n",
    "def get_all_incidents():\n",
    "    \"\"\"Get all incidents as DataFrame.\"\"\"\n",
    "    conn = connect_database()\n",
    "    df = pd.read_sql_query(\n",
    "        \"SELECT * FROM cyber_incidents ORDER BY id DESC\",\n",
    "        conn\n",
    "    )\n",
    "    conn.close()\n",
    "    return df\n",
    "```\n",
    "\n",
    "#### ðŸ“„ `app/services/user_service.py` â€” User Business Logic\n",
    "**Purpose**: Authentication and user migration\n",
    "\n",
    "```python\n",
    "import bcrypt\n",
    "from pathlib import Path\n",
    "from app.data.db import connect_database\n",
    "from app.data.users import get_user_by_username, insert_user\n",
    "from app.data.schema import create_users_table\n",
    "\n",
    "def register_user(username, password, role='user'):\n",
    "    \"\"\"Register new user with password hashing.\"\"\"\n",
    "    # Hash password\n",
    "    password_hash = bcrypt.hashpw(\n",
    "        password.encode('utf-8'),\n",
    "        bcrypt.gensalt()\n",
    "    ).decode('utf-8')\n",
    "    \n",
    "    # Insert into database\n",
    "    insert_user(username, password_hash, role)\n",
    "    return True, f\"User '{username}' registered successfully.\"\n",
    "\n",
    "def login_user(username, password):\n",
    "    \"\"\"Authenticate user.\"\"\"\n",
    "    user = get_user_by_username(username)\n",
    "    if not user:\n",
    "        return False, \"User not found.\"\n",
    "    \n",
    "    # Verify password\n",
    "    stored_hash = user[2]  # password_hash column\n",
    "    if bcrypt.checkpw(password.encode('utf-8'), stored_hash.encode('utf-8')):\n",
    "        return True, f\"Login successful!\"\n",
    "    return False, \"Incorrect password.\"\n",
    "\n",
    "def migrate_users_from_file(filepath='DATA/users.txt'):\n",
    "    \"\"\"Migrate users from text file to database.\"\"\"\n",
    "    # ... migration logic ...\n",
    "```\n",
    "\n",
    "#### `main.py` â€” Demo Script (Entry Point)\n",
    "**Purpose**: Demonstrate all functionality\n",
    "\n",
    "```python\n",
    "from app.data.db import connect_database\n",
    "from app.data.schema import create_all_tables\n",
    "from app.services.user_service import register_user, login_user, migrate_users_from_file\n",
    "from app.data.incidents import insert_incident, get_all_incidents\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Week 8: Database Demo\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Setup database\n",
    "    conn = connect_database()\n",
    "    create_all_tables(conn)\n",
    "    conn.close()\n",
    "    \n",
    "    # 2. Migrate users\n",
    "    migrate_users_from_file()\n",
    "    \n",
    "    # 3. Test authentication\n",
    "    success, msg = register_user(\"alice\", \"SecurePass123!\", \"analyst\")\n",
    "    print(msg)\n",
    "    \n",
    "    success, msg = login_user(\"alice\", \"SecurePass123!\")\n",
    "    print(msg)\n",
    "    \n",
    "    # 4. Test CRUD\n",
    "    incident_id = insert_incident(\n",
    "        \"2024-11-05\",\n",
    "        \"Phishing\",\n",
    "        \"High\",\n",
    "        \"Open\",\n",
    "        \"Suspicious email detected\",\n",
    "        \"alice\"\n",
    "    )\n",
    "    print(f\"Created incident #{incident_id}\")\n",
    "    \n",
    "    # 5. Query data\n",
    "    df = get_all_incidents()\n",
    "    print(f\"Total incidents: {len(df)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  Development Workflow\n",
    "\n",
    "### How to Work with This Structure\n",
    "\n",
    "**While developing in this notebook:**\n",
    "1. Write and test functions here first\n",
    "2. Make sure each function works correctly\n",
    "3. Once tested, copy functions to the appropriate file\n",
    "\n",
    "**After the notebook:**\n",
    "1. Create the file structure shown above\n",
    "2. Copy functions from this notebook to their respective files\n",
    "3. Add proper imports between files\n",
    "4. Test by running `main.py`\n",
    "\n",
    "### Beginner Tip: Don't Worry!\n",
    "\n",
    "**For now**, focus on learning the functions in this notebook. At the end, we'll show you exactly how to organize everything into files. Think of this notebook as your **workshop** where you build and test each piece before assembling the final project.\n",
    "\n",
    "---\n",
    "\n",
    "## Creating Python Packages\n",
    "\n",
    "### What is `__init__.py`?\n",
    "\n",
    "You'll notice `__init__.py` files in the structure. These make folders into **Python packages** so you can import from them.\n",
    "\n",
    "**Create empty `__init__.py` files:**\n",
    "```bash\n",
    "touch app/__init__.py\n",
    "touch app/data/__init__.py\n",
    "touch app/services/__init__.py\n",
    "```\n",
    "\n",
    "Or in Python:\n",
    "```python\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"app/__init__.py\").touch()\n",
    "Path(\"app/data/__init__.py\").touch()\n",
    "Path(\"app/services/__init__.py\").touch()\n",
    "```\n",
    "\n",
    "### How Imports Work\n",
    "\n",
    "Once you have this structure, you can import like this:\n",
    "\n",
    "```python\n",
    "# From main.py\n",
    "from app.data.db import connect_database\n",
    "from app.data.incidents import insert_incident, get_all_incidents\n",
    "from app.services.user_service import register_user, login_user\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "why_db",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Why Move from Files to Databases?\n",
    "\n",
    "### Understanding the Problem\n",
    "\n",
    "In Week 7, you stored users in `users.txt`. This works for small projects, but has serious limitations:\n",
    "\n",
    "| **File Storage** (`users.txt`) | **Database** (`intelligence_platform.db`) |\n",
    "|--------------------------------|-------------------------------------------|\n",
    "| Slow search (must read entire file) | âš¡ Fast search with SQL queries |\n",
    "| No relationships between data |  Link users to incidents, tickets, etc. |\n",
    "| Risk of corruption | ACID-safe (Atomicity, Consistency, Isolation, Durability) |\n",
    "| Manual parsing required | Powerful query language (SQL) |\n",
    "| Single-user access | Multi-user support |\n",
    "\n",
    "### Your Database Schema\n",
    "\n",
    "You'll create **4 tables**:\n",
    "\n",
    "1. **`users`** â€” User accounts with authentication\n",
    "2. **`cyber_incidents`** â€” Security incidents (your chosen domain)\n",
    "3. **`datasets_metadata`** â€” Dataset information\n",
    "4. **`it_tickets`** â€” IT support tickets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2",
   "metadata": {},
   "source": [
    "## Part 2: Database Connection Functions\n",
    "\n",
    "### Step 2.1: Create Connection Function\n",
    "\n",
    "First, we need a function to connect to our database. This function will:\n",
    "- Create the database file if it doesn't exist\n",
    "- Return a connection object that we can use to run SQL commands\n",
    "\n",
    " **Beginner Tip**: Think of `conn` (connection) as a phone line to your database. You need it to send commands and get responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "connect_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_database(db_path=DB_PATH):\n",
    "    \"\"\"\n",
    "    Connect to the SQLite database.\n",
    "    Creates the database file if it doesn't exist.\n",
    "    \n",
    "    Args:\n",
    "        db_path: Path to the database file\n",
    "        \n",
    "    Returns:\n",
    "        sqlite3.Connection: Database connection object\n",
    "    \"\"\"\n",
    "    return sqlite3.connect(str(db_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "495caf56-1919-4531-b428-089cd1fb3c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Connection at 0x201b63407c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = connect_database()\n",
    "conn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5a9d451d-1083-4c46-a3e8-512f457c04b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_tables(conn):\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Users table\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS users (\n",
    "        username TEXT PRIMARY KEY,\n",
    "        password TEXT NOT NULL\n",
    "    )\n",
    "    \"\"\")\n",
    "    \n",
    "    # Cyber incidents table\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS cyber_incidents (\n",
    "        incident_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        incident_date TEXT,\n",
    "        incident_type TEXT,\n",
    "        severity TEXT,\n",
    "        status TEXT,\n",
    "        description TEXT,\n",
    "        reported_by TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "    \n",
    "    # Datasets metadata table\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS datasets_metadata (\n",
    "        dataset_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        domain TEXT,\n",
    "        source TEXT,\n",
    "        description TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "    \n",
    "    # IT tickets table\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS it_tickets (\n",
    "        ticket_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        title TEXT,\n",
    "        description TEXT,\n",
    "        priority TEXT,\n",
    "        status TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "    \n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "42d8299e-9ecb-4f66-b1a7-c63abe006916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tables created successfully!\n"
     ]
    }
   ],
   "source": [
    "conn = connect_database()\n",
    "create_all_tables(conn)\n",
    "conn.close()\n",
    "print(\"All tables created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Create Database Tables\n",
    "\n",
    "### Step 3.1: Create the `users` Table\n",
    "\n",
    "Let's start by creating a table for users. This table will store:\n",
    "- `id` â€” Unique identifier (auto-incremented)\n",
    "- `username` â€” User's login name (must be unique)\n",
    "- `password_hash` â€” Hashed password (from bcrypt)\n",
    "- `role` â€” User role (e.g., 'user', 'analyst', 'admin')\n",
    "\n",
    "ðŸ’¡ **Beginner Tip**: `CREATE TABLE IF NOT EXISTS` means \"create this table only if it doesn't already exist\". This prevents errors if you run the code multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "create_users_table",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_users_table(conn):\n",
    "    \"\"\"\n",
    "    Create the users table if it doesn't exist.\n",
    "    \n",
    "    This is a COMPLETE IMPLEMENTATION as an example.\n",
    "    Study this carefully before implementing the other tables!\n",
    "    \n",
    "    Args:\n",
    "        conn: Database connection object\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # SQL statement to create users table\n",
    "    create_table_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS users (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        username TEXT NOT NULL UNIQUE,\n",
    "        password_hash TEXT NOT NULL,\n",
    "        role TEXT DEFAULT 'user',\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.execute(create_table_sql)\n",
    "    conn.commit()\n",
    "    print(\"âœ… Users table created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create_domain_tables",
   "metadata": {},
   "source": [
    "### Step 3.2: Create Domain Tables\n",
    "\n",
    "Now let's create tables for your three domains. Each table will have columns matching your CSV files.\n",
    "\n",
    "#### Security Note: Foreign Keys\n",
    "\n",
    "Notice that `cyber_incidents` has a `FOREIGN KEY` that references `users(username)`. This creates a **relationship** between tables:\n",
    "- Each incident can be linked to the user who reported it\n",
    "- This is one of the key advantages of databases over text files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "create_domain_tables_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Users table created successfully!\n",
      "âœ… Cyber incidents table created successfully!\n",
      "âœ… Datasets metadata table created successfully!\n",
      "âœ… IT tickets table created successfully!\n"
     ]
    }
   ],
   "source": [
    "# --- Users table ---\n",
    "def create_users_table(conn):\n",
    "    cursor = conn.cursor()\n",
    "    create_table_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS users (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        username TEXT NOT NULL UNIQUE,\n",
    "        password_hash TEXT NOT NULL,\n",
    "        role TEXT DEFAULT 'user',\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_sql)\n",
    "    conn.commit()\n",
    "    print(\"âœ… Users table created successfully!\")\n",
    "\n",
    "# --- Cyber Incidents table ---\n",
    "def create_cyber_incidents_table(conn):\n",
    "    cursor = conn.cursor()\n",
    "    create_table_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS cyber_incidents (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        date TEXT,\n",
    "        incident_type TEXT,\n",
    "        severity TEXT,\n",
    "        status TEXT,\n",
    "        description TEXT,\n",
    "        reported_by TEXT,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_sql)\n",
    "    conn.commit()\n",
    "    print(\"âœ… Cyber incidents table created successfully!\")\n",
    "\n",
    "# --- Datasets Metadata table ---\n",
    "def create_datasets_metadata_table(conn):\n",
    "    cursor = conn.cursor()\n",
    "    create_table_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS datasets_metadata (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        dataset_name TEXT NOT NULL,\n",
    "        category TEXT,\n",
    "        source TEXT,\n",
    "        last_updated TEXT,\n",
    "        record_count INTEGER,\n",
    "        file_size_mb REAL,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_sql)\n",
    "    conn.commit()\n",
    "    print(\"âœ… Datasets metadata table created successfully!\")\n",
    "\n",
    "# --- IT Tickets table ---\n",
    "def create_it_tickets_table(conn):\n",
    "    cursor = conn.cursor()\n",
    "    create_table_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS it_tickets (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        ticket_id TEXT UNIQUE NOT NULL,\n",
    "        priority TEXT,\n",
    "        status TEXT,\n",
    "        category TEXT,\n",
    "        subject TEXT NOT NULL,\n",
    "        description TEXT,\n",
    "        created_date TEXT,\n",
    "        resolved_date TEXT,\n",
    "        assigned_to TEXT,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_sql)\n",
    "    conn.commit()\n",
    "    print(\"âœ… IT tickets table created successfully!\")\n",
    "\n",
    "# --- Run all tables ---\n",
    "conn = connect_database()  # make sure your database connection function exists\n",
    "create_users_table(conn)\n",
    "create_cyber_incidents_table(conn)\n",
    "create_datasets_metadata_table(conn)\n",
    "create_it_tickets_table(conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Migrate Users from Week 7\n",
    "\n",
    "### Step 4.1: Understanding Migration\n",
    "\n",
    "**Migration** means copying data from an old format (text file) to a new format (database table).\n",
    "\n",
    "Your `users.txt` file from Week 7 has this format:\n",
    "```\n",
    "username,password_hash,role\n",
    "alice,$2b$12$...,analyst\n",
    "bob,$2b$12$...,user\n",
    "```\n",
    "\n",
    "We need to:\n",
    "1. Read each line from `users.txt`\n",
    "2. Parse the username, password_hash, and role\n",
    "3. INSERT each user into the `users` table\n",
    "\n",
    "### Step 4.2: Create Migration Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "migrate_users",
   "metadata": {},
   "outputs": [],
   "source": [
    "def migrate_users_from_file(conn, filepath=DATA_DIR / \"users.txt\"):\n",
    "    \"\"\"\n",
    "    Migrate users from users.txt to the database.\n",
    "    \n",
    "    This is a COMPLETE IMPLEMENTATION as an example.\n",
    "    \n",
    "    Args:\n",
    "        conn: Database connection\n",
    "        filepath: Path to users.txt file\n",
    "    \"\"\"\n",
    "    if not filepath.exists():\n",
    "        print(f\"âš ï¸  File not found: {filepath}\")\n",
    "        print(\"   No users to migrate.\")\n",
    "        return\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    migrated_count = 0\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            # Parse line: username,password_hash\n",
    "            parts = line.split(',')\n",
    "            if len(parts) >= 2:\n",
    "                username = parts[0]\n",
    "                password_hash = parts[1]\n",
    "                \n",
    "                # Insert user (ignore if already exists)\n",
    "                try:\n",
    "                    cursor.execute(\n",
    "                        \"INSERT OR IGNORE INTO users (username, password_hash, role) VALUES (?, ?, ?)\",\n",
    "                        (username, password_hash, 'user')\n",
    "                    )\n",
    "                    if cursor.rowcount > 0:\n",
    "                        migrated_count += 1\n",
    "                except sqlite3.Error as e:\n",
    "                    print(f\"Error migrating user {username}: {e}\")\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"âœ… Migrated {migrated_count} users from {filepath.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify_migration",
   "metadata": {},
   "source": [
    "### Step 4.3: Verify Migration\n",
    "\n",
    "Let's check that the users were actually inserted into the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7b87151-b203-4682-a7e1-034f211b7df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def migrate_users(conn, users_file='users.txt'):\n",
    "    \"\"\"\n",
    "    Migrate users from a text file into the users table.\n",
    "    \n",
    "    Args:\n",
    "        conn: Database connection object\n",
    "        users_file: Path to users.txt file\n",
    "    \"\"\"\n",
    "    import os\n",
    "\n",
    "    # This line checks if the file exists\n",
    "    if not os.path.exists(users_file):\n",
    "        print(f\"File '{users_file}' not found!\")\n",
    "        return\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    with open(users_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Skip header\n",
    "    for line in lines[1:]:\n",
    "        line = line.strip()\n",
    "        if line:  # ignore empty lines\n",
    "            username, password_hash, role = line.split(',')\n",
    "            \n",
    "            # Insert into users table\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT OR IGNORE INTO users (username, password_hash, role)\n",
    "                VALUES (?, ?, ?)\n",
    "            \"\"\", (username, password_hash, role))\n",
    "    \n",
    "    conn.commit()\n",
    "    print(\"Users migrated successfully from users.txt!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fea249e-30e9-4dfa-bcd3-c18d48d5e67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users migrated successfully from users.txt!\n"
     ]
    }
   ],
   "source": [
    "conn = connect_database()  # connect to your database\n",
    "migrate_users(conn)         # migrate users from users.txt\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3d2df75-948f-4dfc-9fa3-158384d4b395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Spark\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "verify_migration_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Users in database:\n",
      "ID    Username        Role      \n",
      "-----------------------------------\n",
      "\n",
      "Total users: 0\n"
     ]
    }
   ],
   "source": [
    "conn = connect_database()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT id, username, role FROM users\")\n",
    "users = cursor.fetchall()\n",
    "\n",
    "print(\" Users in database:\")\n",
    "print(f\"{'ID':<5} {'Username':<15} {'Role':<10}\")\n",
    "print(\"-\" * 35)\n",
    "for user in users:\n",
    "    print(f\"{user[0]:<5} {user[1]:<15} {user[2]:<10}\")\n",
    "\n",
    "print(f\"\\nTotal users: {len(users)}\")\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ac4dc57-764c-4935-b6b1-adcb7168faf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in database: []\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"mydatabase.db\")  # make sure this is the same DB youâ€™ve been using\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# List all tables\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "print(\"Tables in database:\", tables)\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8d1124f-e114-4bf9-896b-d17f807c9c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Users table created!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"mydatabase.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the users table\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS users (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    username TEXT NOT NULL UNIQUE,\n",
    "    password_hash TEXT NOT NULL,\n",
    "    role TEXT DEFAULT 'user',\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"âœ… Users table created!\")\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c92c451b-d32c-48d3-be18-4b2527f8cb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users migrated successfully from users.txt!\n"
     ]
    }
   ],
   "source": [
    "def migrate_users(conn, users_file='users.txt'):\n",
    "    import os\n",
    "    if not os.path.exists(users_file):\n",
    "        print(f\"File '{users_file}' not found in {os.getcwd()}!\")\n",
    "        return\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "    with open(users_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    for line in lines[1:]:  # skip header\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            username, password_hash, role = line.split(',')\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT OR IGNORE INTO users (username, password_hash, role)\n",
    "                VALUES (?, ?, ?)\n",
    "            \"\"\", (username, password_hash, role))\n",
    "    \n",
    "    conn.commit()\n",
    "    print(\"Users migrated successfully from users.txt!\")\n",
    "\n",
    "# Run migration\n",
    "conn = sqlite3.connect(\"mydatabase.db\")\n",
    "migrate_users(conn)\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7c52c7f-388c-4ee2-a86d-be0dc1db2b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Users in database:\n",
      "ID    Username        Role      \n",
      "-----------------------------------\n",
      "1     ivan            user      \n",
      "2     alice           analyst   \n",
      "3     bob             user      \n",
      "\n",
      "Total users: 3\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"mydatabase.db\")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT id, username, role FROM users\")\n",
    "users = cursor.fetchall()\n",
    "\n",
    "print(\" Users in database:\")\n",
    "print(f\"{'ID':<5} {'Username':<15} {'Role':<10}\")\n",
    "print(\"-\" * 35)\n",
    "for user in users:\n",
    "    print(f\"{user[0]:<5} {user[1]:<15} {user[2]:<10}\")\n",
    "\n",
    "print(f\"\\nTotal users: {len(users)}\")\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Authentication Functions (Database-Backed)\n",
    "\n",
    "### Step 5.1: Register Function\n",
    "\n",
    "Now that users are in the database, we need to update our authentication to work with the database instead of `users.txt`.\n",
    "\n",
    "The `register()` function will:\n",
    "1. Check if username already exists\n",
    "2. Hash the password with bcrypt\n",
    "3. INSERT the new user into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "register_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_user(username, password, role=\"user\"):\n",
    "    \"\"\"\n",
    "    Register a new user in the database.\n",
    "    \n",
    "    This is a COMPLETE IMPLEMENTATION as an example.\n",
    "    \n",
    "    Args:\n",
    "        username: User's login name\n",
    "        password: Plain text password (will be hashed)\n",
    "        role: User role (default: 'user')\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (success: bool, message: str)\n",
    "    \"\"\"\n",
    "    conn = connect_database()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Check if user already exists\n",
    "    cursor.execute(\"SELECT * FROM users WHERE username = ?\", (username,))\n",
    "    if cursor.fetchone():\n",
    "        conn.close()\n",
    "        return False, f\"Username '{username}' already exists.\"\n",
    "    \n",
    "    # Hash the password\n",
    "    password_bytes = password.encode('utf-8')\n",
    "    salt = bcrypt.gensalt()\n",
    "    hashed = bcrypt.hashpw(password_bytes, salt)\n",
    "    password_hash = hashed.decode('utf-8')\n",
    "    \n",
    "    # Insert new user\n",
    "    cursor.execute(\n",
    "        \"INSERT INTO users (username, password_hash, role) VALUES (?, ?, ?)\",\n",
    "        (username, password_hash, role)\n",
    "    )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    return True, f\"User '{username}' registered successfully!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "login_func_section",
   "metadata": {},
   "source": [
    "### Step 5.2: Login Function\n",
    "\n",
    "The `login()` function will:\n",
    "1. Look up the user in the database\n",
    "2. Retrieve their stored password hash\n",
    "3. Verify the provided password against the hash using bcrypt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "login_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def login_user(username, password):\n",
    "    \"\"\"\n",
    "    Authenticate a user against the database.\n",
    "    \n",
    "    This is a COMPLETE IMPLEMENTATION as an example.\n",
    "    \n",
    "    Args:\n",
    "        username: User's login name\n",
    "        password: Plain text password to verify\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (success: bool, message: str)\n",
    "    \"\"\"\n",
    "    conn = connect_database()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Find user\n",
    "    cursor.execute(\"SELECT * FROM users WHERE username = ?\", (username,))\n",
    "    user = cursor.fetchone()\n",
    "    conn.close()\n",
    "    \n",
    "    if not user:\n",
    "        return False, \"Username not found.\"\n",
    "    \n",
    "    # Verify password (user[2] is password_hash column)\n",
    "    stored_hash = user[2]\n",
    "    password_bytes = password.encode('utf-8')\n",
    "    hash_bytes = stored_hash.encode('utf-8')\n",
    "    \n",
    "    if bcrypt.checkpw(password_bytes, hash_bytes):\n",
    "        return True, f\"Welcome, {username}!\"\n",
    "    else:\n",
    "        return False, \"Invalid password.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Load CSV Data with Pandas\n",
    "\n",
    "### Step 6.1: Understanding Bulk Loading\n",
    "\n",
    "Now that your tables exist, you can load the provided CSV files. Pandas makes this incredibly easy with the `to_sql()` method.\n",
    "\n",
    " **Beginner Tip**: \n",
    "- `if_exists='append'` means \"add to existing data\"\n",
    "- `if_exists='replace'` means \"delete old data and insert new\"\n",
    "- `index=False` means \"don't save the DataFrame index as a column\"\n",
    "\n",
    "### Step 6.2: Create CSV Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "load_csv_func",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0e54cc3d-71d2-421a-88ed-e3325eab8423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_to_table(conn, csv_filename, table_name, drop_id=True):\n",
    "    csv_file = DATA_PATH / csv_filename\n",
    "    if not csv_file.exists():\n",
    "        print(f\"CSV file not found: {csv_file}\")\n",
    "        return 0\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Drop ID columns if needed\n",
    "    if drop_id:\n",
    "        for col in df.columns:\n",
    "            if col.lower().endswith(\"_id\"):\n",
    "                df = df.drop(columns=[col])\n",
    "    \n",
    "    # Rename CSV columns to match table schema\n",
    "    if table_name == \"cyber_incidents\":\n",
    "        rename_map = {}\n",
    "        if \"date\" in df.columns:\n",
    "            rename_map[\"date\"] = \"incident_date\"\n",
    "        if \"type\" in df.columns:\n",
    "            rename_map[\"type\"] = \"incident_type\"\n",
    "        df = df.rename(columns=rename_map)\n",
    "    \n",
    "    df.to_sql(table_name, conn, if_exists=\"append\", index=False)\n",
    "    print(f\"Loaded {len(df)} rows into '{table_name}' from '{csv_file}'\")\n",
    "    return len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7b468284-7526-47a1-9955-fad88a2f412a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files created and fixed for database setup!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure the /data directory exists\n",
    "data_dir = Path(\"data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# -------- cyber_incidents.csv --------\n",
    "cyber_incidents_data = [\n",
    "    [\"incident_id\", \"incident_date\", \"incident_type\", \"severity\", \"status\", \"description\", \"reported_by\"],\n",
    "    [1, \"2024-01-05\", \"Phishing\", \"High\", \"Open\", \"Employee received fraudulent email\", \"Alice\"],\n",
    "    [2, \"2024-02-12\", \"Malware\", \"Medium\", \"Investigating\", \"Detected suspicious executable on workstation\", \"Bob\"],\n",
    "    [3, \"2024-03-20\", \"DDoS\", \"Critical\", \"Resolved\", \"Massive traffic spike impacting services\", \"Charlie\"],\n",
    "]\n",
    "\n",
    "with open(data_dir / \"cyber_incidents.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(cyber_incidents_data)\n",
    "\n",
    "# -------- datasets_metadata.csv --------\n",
    "datasets_metadata_data = [\n",
    "    [\"dataset_id\", \"domain\", \"source\", \"description\"],\n",
    "    [1, \"Business\", \"Customer Data\", \"Contains customer info\"],\n",
    "    [2, \"Cybersecurity\", \"Network Activity Log\", \"Logs of network activity\"],\n",
    "    [3, \"IT Support\", \"Ticket History\", \"History of IT tickets\"],\n",
    "]\n",
    "\n",
    "with open(data_dir / \"datasets_metadata.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(datasets_metadata_data)\n",
    "\n",
    "# -------- it_tickets.csv --------\n",
    "it_tickets_data = [\n",
    "    [\"ticket_id\", \"title\", \"description\", \"priority\", \"status\"],\n",
    "    [1, \"Hardware issue\", \"PC not turning on\", \"High\", \"Open\"],\n",
    "    [2, \"Network outage\", \"Wi-Fi down on 2nd floor\", \"Medium\", \"Closed\"],\n",
    "    [3, \"Software bug\", \"App crashes on login\", \"Low\", \"In Progress\"],\n",
    "]\n",
    "\n",
    "with open(data_dir / \"it_tickets.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(it_tickets_data)\n",
    "\n",
    "print(\"CSV files created and fixed for database setup!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3109ae7c-4790-4b6f-8be7-3f97c2a24f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 rows into 'cyber_incidents' table from 'data/cyber_incidents.csv'\n",
      "Loaded 3 rows into 'datasets_metadata' table from 'data/datasets_metadata.csv'\n",
      "Loaded 3 rows into 'it_tickets' table from 'data/it_tickets.csv'\n"
     ]
    }
   ],
   "source": [
    "conn = connect_database()\n",
    "\n",
    "load_csv_to_table(conn, \"data/cyber_incidents.csv\", \"cyber_incidents\")\n",
    "load_csv_to_table(conn, \"data/datasets_metadata.csv\", \"datasets_metadata\")\n",
    "load_csv_to_table(conn, \"data/it_tickets.csv\", \"it_tickets\")\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: CRUD Operations\n",
    "\n",
    "### Understanding CRUD\n",
    "\n",
    "**CRUD** stands for the four basic operations you can perform on database data:\n",
    "\n",
    "| Operation | SQL Command | What It Does |\n",
    "|-----------|-------------|-------------|\n",
    "| **C**reate | `INSERT` | Add new records |\n",
    "| **R**ead | `SELECT` | Retrieve existing records |\n",
    "| **U**pdate | `UPDATE` | Modify existing records |\n",
    "| **D**elete | `DELETE` | Remove records |\n",
    "\n",
    "###  Security: Parameterized Queries\n",
    "\n",
    "**CRITICAL**: Always use `?` placeholders and pass values as a tuple to prevent SQL injection attacks!\n",
    "\n",
    " **NEVER DO THIS** (vulnerable to SQL injection):\n",
    "```python\n",
    "query = f\"SELECT * FROM users WHERE username = '{username}'\"\n",
    "```\n",
    "\n",
    " **ALWAYS DO THIS** (safe):\n",
    "```python\n",
    "query = \"SELECT * FROM users WHERE username = ?\"\n",
    "cursor.execute(query, (username,))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 7.1: CREATE â€” Insert New Incident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f7ef7b8c-1c3f-4d23-8da4-be5f97ecc0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'status' added successfully.\n"
     ]
    }
   ],
   "source": [
    "conn = connect_database()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Add a 'status' column if it doesn't exist yet\n",
    "try:\n",
    "    cursor.execute(\"ALTER TABLE cyber_incidents ADD COLUMN status TEXT\")\n",
    "    print(\"Column 'status' added successfully.\")\n",
    "except:\n",
    "    print(\"Column 'status' already exists or error occurred.\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "create_incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_incident(conn, date, incident_type, severity, description, status=None, reported_by=None):\n",
    "    \"\"\"\n",
    "    Insert a new cyber incident into the database.\n",
    "    \n",
    "    Args:\n",
    "        conn: Database connection\n",
    "        date: Incident date (YYYY-MM-DD)\n",
    "        incident_type: Type of incident\n",
    "        severity: Severity level\n",
    "        description: Incident description\n",
    "        status: Current status (optional, will add column if needed)\n",
    "        reported_by: Username of reporter (optional)\n",
    "        \n",
    "    Returns:\n",
    "        int: ID of the inserted incident\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Ensure the 'status' column exists\n",
    "    try:\n",
    "        cursor.execute(\"ALTER TABLE cyber_incidents ADD COLUMN status TEXT\")\n",
    "    except:\n",
    "        pass  # column already exists\n",
    "    \n",
    "    query = \"\"\"\n",
    "        INSERT INTO cyber_incidents (date, type, severity, description, status, reported_by)\n",
    "        VALUES (?, ?, ?, ?, ?, ?)\n",
    "    \"\"\"\n",
    "    cursor.execute(query, (date, incident_type, severity, description, status, reported_by))\n",
    "    conn.commit()\n",
    "    \n",
    "    return cursor.lastrowid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "read_section",
   "metadata": {},
   "source": [
    "### Step 7.2: READ â€” Query Incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "read_incidents",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_all_incidents(conn):\n",
    "    \"\"\"\n",
    "    Retrieve all incidents from the database using pandas.\n",
    "\n",
    "    Args:\n",
    "        conn: Database connection\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: All incidents\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(\"SELECT * FROM cyber_incidents\", conn)\n",
    "    return df\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "update_section",
   "metadata": {},
   "source": [
    "### Step 7.3: UPDATE â€” Modify Incident Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "update_incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_incident_description(conn, incident_id, new_description):\n",
    "    \"\"\"\n",
    "    Update the description of an incident.\n",
    "\n",
    "    Args:\n",
    "        conn: Database connection\n",
    "        incident_id: ID of the incident to update\n",
    "        new_description: New description text\n",
    "\n",
    "    Returns:\n",
    "        int: Number of rows updated\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Ensure the table has the 'description' column\n",
    "    cursor.execute(\"PRAGMA table_info(cyber_incidents)\")\n",
    "    columns = [col[1] for col in cursor.fetchall()]\n",
    "    if \"description\" not in columns:\n",
    "        cursor.execute(\"ALTER TABLE cyber_incidents ADD COLUMN description TEXT\")\n",
    "        conn.commit()\n",
    "\n",
    "    # Update the description\n",
    "    query = \"UPDATE cyber_incidents SET description = ? WHERE incident_id = ?\"\n",
    "    cursor.execute(query, (new_description, incident_id))\n",
    "    conn.commit()\n",
    "\n",
    "    return cursor.rowcount\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delete_section",
   "metadata": {},
   "source": [
    "### Step 7.4: DELETE â€” Remove Incident\n",
    "\n",
    " **WARNING**: DELETE is permanent! Always use a WHERE clause to avoid deleting all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delete_incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_incident(conn, incident_id):\n",
    "    \"\"\"\n",
    "    Delete an incident from the database.\n",
    "    \n",
    "    TODO: Implement DELETE operation.\n",
    "    \"\"\"\n",
    "    # TODO: Write DELETE SQL: DELETE FROM cyber_incidents WHERE id = ?\n",
    "    # TODO: Execute and commit\n",
    "    # TODO: Return cursor.rowcount\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "84a83101-f102-4af4-856c-4c40c77ce726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_incident(conn, incident_id):\n",
    "    \"\"\"\n",
    "    Delete an incident from the database.\n",
    "    \n",
    "    Args:\n",
    "        conn: Database connection\n",
    "        incident_id: ID of the incident to delete\n",
    "        \n",
    "    Returns:\n",
    "        int: Number of rows deleted\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    query = \"DELETE FROM cyber_incidents WHERE incident_id = ?\"\n",
    "    cursor.execute(query, (incident_id,))\n",
    "    conn.commit()\n",
    "    return cursor.rowcount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fea94135-1b3a-44bf-b382-1ef426d56604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows deleted: 1\n"
     ]
    }
   ],
   "source": [
    "conn = connect_database()\n",
    "rows_deleted = delete_incident(conn, 1)\n",
    "print(f\"Rows deleted: {rows_deleted}\")\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ca7c33a3-db37-40fd-acd4-22435ec24049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'incident_id', 'INTEGER', 0, None, 0)\n",
      "(1, 'date', 'TEXT', 0, None, 0)\n",
      "(2, 'type', 'TEXT', 0, None, 0)\n",
      "(3, 'severity', 'TEXT', 0, None, 0)\n",
      "(4, 'description', 'TEXT', 0, None, 0)\n"
     ]
    }
   ],
   "source": [
    "conn = connect_database()\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"PRAGMA table_info(cyber_incidents)\")\n",
    "columns = cursor.fetchall()\n",
    "for col in columns:\n",
    "    print(col)\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Analytical Queries (The Big 6) - OPTIONAL it couuld be done with pandas\n",
    "\n",
    "### Step 8.1: Using GROUP BY for Aggregation\n",
    "\n",
    "Let's use the **Big 6 SQL clauses** to extract insights from your data:\n",
    "\n",
    "1. **SELECT** â€” Choose what columns to return\n",
    "2. **FROM** â€” Specify the table\n",
    "3. **WHERE** â€” Filter individual rows\n",
    "4. **GROUP BY** â€” Group rows for aggregation\n",
    "5. **HAVING** â€” Filter aggregated groups\n",
    "6. **ORDER BY** â€” Sort the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analytical_queries",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_incidents_by_type_count(conn):\n",
    "    \"\"\"\n",
    "    Count incidents by type.\n",
    "    Uses: SELECT, FROM, GROUP BY, ORDER BY\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT incident_type, COUNT(*) as count\n",
    "    FROM cyber_incidents\n",
    "    GROUP BY incident_type\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    return df\n",
    "\n",
    "def get_high_severity_by_status(conn):\n",
    "    \"\"\"\n",
    "    Count high severity incidents by status.\n",
    "    Uses: SELECT, FROM, WHERE, GROUP BY, ORDER BY\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT status, COUNT(*) as count\n",
    "    FROM cyber_incidents\n",
    "    WHERE severity = 'High'\n",
    "    GROUP BY status\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    return df\n",
    "\n",
    "def get_incident_types_with_many_cases(conn, min_count=5):\n",
    "    \"\"\"\n",
    "    Find incident types with more than min_count cases.\n",
    "    Uses: SELECT, FROM, GROUP BY, HAVING, ORDER BY\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT incident_type, COUNT(*) as count\n",
    "    FROM cyber_incidents\n",
    "    GROUP BY incident_type\n",
    "    HAVING COUNT(*) > ?\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn, params=(min_count,))\n",
    "    return df\n",
    "\n",
    "# Test: Run analytical queries\n",
    "conn = connect_database()\n",
    "\n",
    "print(\"\\n Incidents by Type:\")\n",
    "df_by_type = get_incidents_by_type_count(conn)\n",
    "print(df_by_type)\n",
    "\n",
    "print(\"\\n High Severity Incidents by Status:\")\n",
    "df_high_severity = get_high_severity_by_status(conn)\n",
    "print(df_high_severity)\n",
    "\n",
    "print(\"\\n Incident Types with Many Cases (>5):\")\n",
    "df_many_cases = get_incident_types_with_many_cases(conn, min_count=5)\n",
    "print(df_many_cases)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7b059f12-7603-4017-a381-1d63f284750c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Incidents by Type ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malware</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DDoS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type  count\n",
       "0  Malware      1\n",
       "1     DDoS      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== High Severity Incidents by Status ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>severity</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [severity, count]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Incident Types with Many Cases (>5) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [type, count]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_incidents_by_type_count(conn):\n",
    "    \"\"\"\n",
    "    Count incidents by type.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT type, COUNT(*) as count\n",
    "    FROM cyber_incidents\n",
    "    GROUP BY type\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    return df\n",
    "\n",
    "def get_high_severity_by_status(conn):\n",
    "    \"\"\"\n",
    "    Count high severity incidents by status.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT severity, COUNT(*) as count\n",
    "    FROM cyber_incidents\n",
    "    WHERE severity = 'High'\n",
    "    GROUP BY severity\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    return df\n",
    "\n",
    "def get_incident_types_with_many_cases(conn, min_count=5):\n",
    "    \"\"\"\n",
    "    Find incident types with more than min_count cases.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT type, COUNT(*) as count\n",
    "    FROM cyber_incidents\n",
    "    GROUP BY type\n",
    "    HAVING COUNT(*) > ?\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn, params=(min_count,))\n",
    "    return df\n",
    "\n",
    "# Run the queries and display\n",
    "conn = connect_database()\n",
    "\n",
    "print(\"=== Incidents by Type ===\")\n",
    "df_by_type = get_incidents_by_type_count(conn)\n",
    "display(df_by_type)\n",
    "\n",
    "print(\"\\n=== High Severity Incidents by Status ===\")\n",
    "df_high_severity = get_high_severity_by_status(conn)\n",
    "display(df_high_severity)\n",
    "\n",
    "print(\"\\n=== Incident Types with Many Cases (>5) ===\")\n",
    "df_many_cases = get_incident_types_with_many_cases(conn, min_count=5)\n",
    "display(df_many_cases)\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Complete Database Setup Script\n",
    "\n",
    "### Step 9.1: Create a Complete Setup Function\n",
    "\n",
    "Let's create a single function that sets up your entire database from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_database_complete():\n",
    "    \"\"\"\n",
    "    Complete database setup:\n",
    "    1. Connect to database\n",
    "    2. Create all tables\n",
    "    3. Migrate users from users.txt\n",
    "    4. Load CSV data for all domains\n",
    "    5. Verify setup\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STARTING COMPLETE DATABASE SETUP\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Step 1: Connect\n",
    "    print(\"\\n[1/5] Connecting to database...\")\n",
    "    conn = connect_database()\n",
    "    print(\"       Connected\")\n",
    "    \n",
    "    # Step 2: Create tables\n",
    "    print(\"\\n[2/5] Creating database tables...\")\n",
    "    create_all_tables(conn)\n",
    "    \n",
    "    # Step 3: Migrate users\n",
    "    print(\"\\n[3/5] Migrating users from users.txt...\")\n",
    "    user_count = migrate_users_from_file(conn)\n",
    "    print(f\"       Migrated {user_count} users\")\n",
    "    \n",
    "    # Step 4: Load CSV data\n",
    "    print(\"\\n[4/5] Loading CSV data...\")\n",
    "    total_rows = load_all_csv_data(conn)\n",
    "    \n",
    "    # Step 5: Verify\n",
    "    print(\"\\n[5/5] Verifying database setup...\")\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Count rows in each table\n",
    "    tables = ['users', 'cyber_incidents', 'datasets_metadata', 'it_tickets']\n",
    "    print(\"\\n Database Summary:\")\n",
    "    print(f\"{'Table':<25} {'Row Count':<15}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for table in tables:\n",
    "        cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n",
    "        count = cursor.fetchone()[0]\n",
    "        print(f\"{table:<25} {count:<15}\")\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\" DATABASE SETUP COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n Database location: {DB_PATH.resolve()}\")\n",
    "    print(\"\\nYou're ready for Week 9 (Streamlit web interface)!\")\n",
    "\n",
    "# Run the complete setup\n",
    "setup_database_complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "167a40aa-ade5-4d29-822c-bfbb72dba405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STARTING COMPLETE DATABASE SETUP\n",
      "============================================================\n",
      "[1/5] Connecting to database...\n",
      "       Connected\n",
      "[2/5] Creating tables...\n",
      "All old tables dropped.\n",
      "All tables created successfully!\n",
      "[3/5] Migrating users...\n",
      "File not found: data\\users.txt\n",
      "       Migrated 0 users\n",
      "[4/5] Loading CSV data...\n",
      "Loaded 3 rows into 'cyber_incidents' from 'data\\cyber_incidents.csv'\n",
      "Loaded 3 rows into 'datasets_metadata' from 'data\\datasets_metadata.csv'\n",
      "Loaded 3 rows into 'it_tickets' from 'data\\it_tickets.csv'\n",
      "       Loaded 9 rows in total\n",
      "[5/5] Verifying tables...\n",
      "Table                     Row Count      \n",
      "----------------------------------------\n",
      "users                     0              \n",
      "cyber_incidents           3              \n",
      "datasets_metadata         3              \n",
      "it_tickets                3              \n",
      "\n",
      "DATABASE SETUP COMPLETE!\n",
      "Database location: C:\\Users\\Spark\\multi_domain.db\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------\n",
    "# Paths\n",
    "# -----------------------\n",
    "DB_PATH = Path(\"multi_domain.db\")\n",
    "DATA_PATH = Path(\"data\")\n",
    "\n",
    "# -----------------------\n",
    "# Database Connection\n",
    "# -----------------------\n",
    "def connect_database(db_path=DB_PATH):\n",
    "    return sqlite3.connect(str(db_path))\n",
    "\n",
    "# -----------------------\n",
    "# Drop all tables (start fresh)\n",
    "# -----------------------\n",
    "def drop_all_tables(conn):\n",
    "    cursor = conn.cursor()\n",
    "    tables = ['users', 'cyber_incidents', 'datasets_metadata', 'it_tickets']\n",
    "    for table in tables:\n",
    "        cursor.execute(f\"DROP TABLE IF EXISTS {table}\")\n",
    "    conn.commit()\n",
    "    print(\"All old tables dropped.\")\n",
    "\n",
    "# -----------------------\n",
    "# Create all tables\n",
    "# -----------------------\n",
    "def create_all_tables(conn):\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS users (\n",
    "        username TEXT PRIMARY KEY,\n",
    "        password TEXT NOT NULL\n",
    "    )\n",
    "    \"\"\")\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS cyber_incidents (\n",
    "        incident_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        incident_date TEXT,\n",
    "        incident_type TEXT,\n",
    "        severity TEXT,\n",
    "        status TEXT,\n",
    "        description TEXT,\n",
    "        reported_by TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS datasets_metadata (\n",
    "        dataset_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        domain TEXT,\n",
    "        source TEXT,\n",
    "        description TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS it_tickets (\n",
    "        ticket_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        title TEXT,\n",
    "        description TEXT,\n",
    "        priority TEXT,\n",
    "        status TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "    print(\"All tables created successfully!\")\n",
    "\n",
    "# -----------------------\n",
    "# Migrate users\n",
    "# -----------------------\n",
    "def migrate_users_from_file(conn):\n",
    "    user_file = DATA_PATH / \"users.txt\"\n",
    "    if not user_file.exists():\n",
    "        print(f\"File not found: {user_file}\")\n",
    "        return 0\n",
    "    \n",
    "    count = 0\n",
    "    with open(user_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            username, password = line.strip().split(\",\")\n",
    "            try:\n",
    "                conn.execute(\"INSERT INTO users (username, password) VALUES (?, ?)\", (username, password))\n",
    "                count += 1\n",
    "            except sqlite3.IntegrityError:\n",
    "                pass  # skip duplicates\n",
    "    conn.commit()\n",
    "    return count\n",
    "\n",
    "# -----------------------\n",
    "# Load CSVs\n",
    "# -----------------------\n",
    "def load_csv_to_table(conn, csv_filename, table_name, drop_id=True):\n",
    "    csv_file = DATA_PATH / csv_filename\n",
    "    if not csv_file.exists():\n",
    "        print(f\"CSV file not found: {csv_file}\")\n",
    "        return 0\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Drop ID columns\n",
    "    if drop_id:\n",
    "        for col in df.columns:\n",
    "            if col.lower().endswith(\"_id\"):\n",
    "                df = df.drop(columns=[col])\n",
    "    \n",
    "    # Rename columns for consistency\n",
    "    if table_name == \"cyber_incidents\" and \"date\" in df.columns:\n",
    "        df = df.rename(columns={\"date\": \"incident_date\"})\n",
    "    \n",
    "    df.to_sql(table_name, conn, if_exists=\"append\", index=False)\n",
    "    print(f\"Loaded {len(df)} rows into '{table_name}' from '{csv_file}'\")\n",
    "    return len(df)\n",
    "\n",
    "def load_all_csv_data(conn):\n",
    "    total_rows = 0\n",
    "    total_rows += load_csv_to_table(conn, \"cyber_incidents.csv\", \"cyber_incidents\")\n",
    "    total_rows += load_csv_to_table(conn, \"datasets_metadata.csv\", \"datasets_metadata\")\n",
    "    total_rows += load_csv_to_table(conn, \"it_tickets.csv\", \"it_tickets\")\n",
    "    return total_rows\n",
    "\n",
    "# -----------------------\n",
    "# Complete Setup\n",
    "# -----------------------\n",
    "def setup_database_complete():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STARTING COMPLETE DATABASE SETUP\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Connect\n",
    "    print(\"[1/5] Connecting to database...\")\n",
    "    conn = connect_database()\n",
    "    print(\"       Connected\")\n",
    "    \n",
    "    # Drop + Create tables\n",
    "    print(\"[2/5] Creating tables...\")\n",
    "    drop_all_tables(conn)\n",
    "    create_all_tables(conn)\n",
    "    \n",
    "    # Migrate users\n",
    "    print(\"[3/5] Migrating users...\")\n",
    "    user_count = migrate_users_from_file(conn)\n",
    "    print(f\"       Migrated {user_count} users\")\n",
    "    \n",
    "    # Load CSVs\n",
    "    print(\"[4/5] Loading CSV data...\")\n",
    "    total_rows = load_all_csv_data(conn)\n",
    "    print(f\"       Loaded {total_rows} rows in total\")\n",
    "    \n",
    "    # Verify tables\n",
    "    print(\"[5/5] Verifying tables...\")\n",
    "    cursor = conn.cursor()\n",
    "    tables = ['users', 'cyber_incidents', 'datasets_metadata', 'it_tickets']\n",
    "    print(f\"{'Table':<25} {'Row Count':<15}\")\n",
    "    print(\"-\"*40)\n",
    "    for table in tables:\n",
    "        cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n",
    "        count = cursor.fetchone()[0]\n",
    "        print(f\"{table:<25} {count:<15}\")\n",
    "    \n",
    "    conn.close()\n",
    "    print(\"\\nDATABASE SETUP COMPLETE!\")\n",
    "    print(f\"Database location: {DB_PATH.resolve()}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# -----------------------\n",
    "# Run setup\n",
    "# -----------------------\n",
    "setup_database_complete()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 10: Testing & Verification\n",
    "\n",
    "### Step 10.1: Comprehensive Database Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_comprehensive_tests():\n",
    "    \"\"\"\n",
    "    Run comprehensive tests on your database.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ§ª RUNNING COMPREHENSIVE TESTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    conn = connect_database()\n",
    "    \n",
    "    # Test 1: Authentication\n",
    "    print(\"\\n[TEST 1] Authentication\")\n",
    "    success, msg = register_user(\"test_user\", \"TestPass123!\", \"user\")\n",
    "    print(f\"  Register: {'âœ…' if success else 'âŒ'} {msg}\")\n",
    "    \n",
    "    success, msg = login_user(\"test_user\", \"TestPass123!\")\n",
    "    print(f\"  Login:    {'âœ…' if success else 'âŒ'} {msg}\")\n",
    "    \n",
    "    # Test 2: CRUD Operations\n",
    "    print(\"\\n[TEST 2] CRUD Operations\")\n",
    "    \n",
    "    # Create\n",
    "    test_id = insert_incident(\n",
    "        conn,\n",
    "        \"2024-11-05\",\n",
    "        \"Test Incident\",\n",
    "        \"Low\",\n",
    "        \"Open\",\n",
    "        \"This is a test incident\",\n",
    "        \"test_user\"\n",
    "    )\n",
    "    print(f\"  Create: âœ… Incident #{test_id} created\")\n",
    "    \n",
    "    # Read\n",
    "    df = pd.read_sql_query(\n",
    "        \"SELECT * FROM cyber_incidents WHERE id = ?\",\n",
    "        conn,\n",
    "        params=(test_id,)\n",
    "    )\n",
    "    print(f\"  Read:    Found incident #{test_id}\")\n",
    "    \n",
    "    # Update\n",
    "    update_incident_status(conn, test_id, \"Resolved\")\n",
    "    print(f\"  Update:  Status updated\")\n",
    "    \n",
    "    # Delete\n",
    "    delete_incident(conn, test_id)\n",
    "    print(f\"  Delete:  Incident deleted\")\n",
    "    \n",
    "    # Test 3: Analytical Queries\n",
    "    print(\"\\n[TEST 3] Analytical Queries\")\n",
    "    \n",
    "    df_by_type = get_incidents_by_type_count(conn)\n",
    "    print(f\"  By Type:     Found {len(df_by_type)} incident types\")\n",
    "    \n",
    "    df_high = get_high_severity_by_status(conn)\n",
    "    print(f\"  High Severity: Found {len(df_high)} status categories\")\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… ALL TESTS PASSED!\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Run tests\n",
    "run_comprehensive_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7beeba9b-aba2-4efe-9ab0-9e5d4313a01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ§ª RUNNING COMPREHENSIVE TESTS\n",
      "============================================================\n",
      "\n",
      "[TEST 1] Authentication\n",
      "  Register: âŒ User already exists\n",
      "  Login:    âœ… User login successful\n",
      "\n",
      "[TEST 2] CRUD Operations\n",
      "  Create: âœ… Incident #5 created\n",
      "  Read:    Found incident #5\n",
      "  Update:  Status updated\n",
      "  Delete:  Incident deleted\n",
      "\n",
      "[TEST 3] Analytical Queries\n",
      "  By Type:     Found 3 incident types\n",
      "  High Severity: Found 1 status categories\n",
      "\n",
      "============================================================\n",
      "âœ… ALL TESTS COMPLETED!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def run_comprehensive_tests():\n",
    "    \"\"\"\n",
    "    Run comprehensive tests on the database matching current schema.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ§ª RUNNING COMPREHENSIVE TESTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    conn = sqlite3.connect(str(DB_PATH))\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # ----------------------\n",
    "    # Test 1: User Authentication\n",
    "    # ----------------------\n",
    "    print(\"\\n[TEST 1] Authentication\")\n",
    "    try:\n",
    "        cursor.execute(\"INSERT INTO users (username, password) VALUES (?, ?)\", (\"test_user\", \"TestPass123!\"))\n",
    "        conn.commit()\n",
    "        print(\"  Register: âœ… User 'test_user' registered\")\n",
    "    except sqlite3.IntegrityError:\n",
    "        print(\"  Register: âŒ User already exists\")\n",
    "    \n",
    "    cursor.execute(\"SELECT password FROM users WHERE username = ?\", (\"test_user\",))\n",
    "    row = cursor.fetchone()\n",
    "    if row and row[0] == \"TestPass123!\":\n",
    "        print(\"  Login:    âœ… User login successful\")\n",
    "    else:\n",
    "        print(\"  Login:    âŒ Login failed\")\n",
    "    \n",
    "    # ----------------------\n",
    "    # Test 2: CRUD Operations on cyber_incidents\n",
    "    # ----------------------\n",
    "    print(\"\\n[TEST 2] CRUD Operations\")\n",
    "    \n",
    "    # Create\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO cyber_incidents\n",
    "        (incident_date, incident_type, severity, status, description, reported_by)\n",
    "        VALUES (?, ?, ?, ?, ?, ?)\n",
    "    \"\"\", (\"2024-11-05\", \"Test Incident\", \"Low\", \"Open\", \"This is a test incident\", \"test_user\"))\n",
    "    conn.commit()\n",
    "    test_id = cursor.lastrowid\n",
    "    print(f\"  Create: âœ… Incident #{test_id} created\")\n",
    "    \n",
    "    # Read\n",
    "    cursor.execute(\"SELECT * FROM cyber_incidents WHERE incident_id = ?\", (test_id,))\n",
    "    row = cursor.fetchone()\n",
    "    if row:\n",
    "        print(f\"  Read:    Found incident #{test_id}\")\n",
    "    else:\n",
    "        print(f\"  Read:    âŒ Incident not found\")\n",
    "    \n",
    "    # Update\n",
    "    cursor.execute(\"UPDATE cyber_incidents SET status = ? WHERE incident_id = ?\", (\"Resolved\", test_id))\n",
    "    conn.commit()\n",
    "    print(\"  Update:  Status updated\")\n",
    "    \n",
    "    # Delete\n",
    "    cursor.execute(\"DELETE FROM cyber_incidents WHERE incident_id = ?\", (test_id,))\n",
    "    conn.commit()\n",
    "    print(\"  Delete:  Incident deleted\")\n",
    "    \n",
    "    # ----------------------\n",
    "    # Test 3: Analytical Queries\n",
    "    # ----------------------\n",
    "    print(\"\\n[TEST 3] Analytical Queries\")\n",
    "    \n",
    "    # Count by type\n",
    "    df_by_type = pd.read_sql_query(\"SELECT incident_type, COUNT(*) as count FROM cyber_incidents GROUP BY incident_type\", conn)\n",
    "    print(f\"  By Type:     Found {len(df_by_type)} incident types\")\n",
    "    \n",
    "    # Count high severity\n",
    "    df_high = pd.read_sql_query(\"SELECT status, COUNT(*) as count FROM cyber_incidents WHERE severity = 'High' GROUP BY status\", conn)\n",
    "    print(f\"  High Severity: Found {len(df_high)} status categories\")\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… ALL TESTS COMPLETED!\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Run the tests\n",
    "run_comprehensive_tests()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Congratulations!\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "You've successfully:\n",
    "\n",
    " **Migrated** from file-based storage to a professional SQLite database  \n",
    " **Created** a complete database schema with 4 tables  \n",
    " **Implemented** secure authentication with bcrypt  \n",
    " **Loaded** CSV data efficiently using pandas  \n",
    " **Built** CRUD functions for all database operations  \n",
    " **Secured** your queries against SQL injection  \n",
    " **Extracted** insights using analytical SQL queries  \n",
    "\n",
    "### Your Database Structure\n",
    "\n",
    "```\n",
    "intelligence_platform.db\n",
    "â”œâ”€ users                 (authentication)\n",
    "â”œâ”€ cyber_incidents       (security domain)\n",
    "â”œâ”€ datasets_metadata     (data domain)\n",
    "â””â”€ it_tickets            (IT domain)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  Next Steps: Week 9 Preview\n",
    "\n",
    "### What's Coming in Week 9\n",
    "\n",
    "Next week, you'll build a **Streamlit web interface** that uses your database:\n",
    "\n",
    "1. **Login Page** â€” Use your `login_user()` function\n",
    "2. **Dashboard** â€” Display incident statistics with charts\n",
    "3. **CRUD Forms** â€” Interactive forms for creating/updating incidents\n",
    "4. **Visualizations** â€” Use Plotly to create interactive charts\n",
    "5. **Session Management** â€” Keep users logged in across pages\n",
    "\n",
    "### Preparing for Week 9\n",
    "\n",
    "Make sure your database is working correctly:\n",
    "-  All tables created\n",
    "-  Data loaded from CSVs\n",
    "-  CRUD operations tested\n",
    "-  Queries returning correct results\n",
    "\n",
    "---\n",
    "\n",
    "##  Submission Checklist\n",
    "\n",
    "Before submitting your Week 8 work, ensure you have:\n",
    "\n",
    "### Files to Submit\n",
    "\n",
    "- [ ] `app/data/db.py` â€” Database connection functions\n",
    "- [ ] `app/data/schema.py` â€” CREATE TABLE statements\n",
    "- [ ] `app/data/users.py` â€” User CRUD functions\n",
    "- [ ] `app/data/incidents.py` â€” Incident CRUD functions\n",
    "- [ ] `app/data/datasets.py` â€” Dataset CRUD functions\n",
    "- [ ] `app/data/tickets.py` â€” Ticket CRUD functions\n",
    "- [ ] `app/services/user_service.py` â€” User migration function\n",
    "- [ ] `main.py` â€” Demo script showing all CRUD operations\n",
    "- [ ] `DATA/intelligence_platform.db` â€” Your populated database\n",
    "- [ ] `requirements.txt` â€” Updated with pandas, bcrypt\n",
    "- [ ] `docs/README.md` â€” Documentation with screenshots\n",
    "\n",
    "### Testing Checklist\n",
    "\n",
    "- [ ] Database connects successfully\n",
    "- [ ] All 4 tables created\n",
    "- [ ] Users migrated from users.txt\n",
    "- [ ] CSV data loaded\n",
    "- [ ] Registration works\n",
    "- [ ] Login works\n",
    "- [ ] Can create new incidents\n",
    "- [ ] Can read/query incidents\n",
    "- [ ] Can update incident status\n",
    "- [ ] Can delete incidents\n",
    "- [ ] Analytical queries return results\n",
    "- [ ] No SQL injection vulnerabilities (all queries use `?` placeholders)\n",
    "\n",
    "---\n",
    "\n",
    "##  Tips & Best Practices\n",
    "\n",
    "### Database Best Practices\n",
    "\n",
    "1. **Always close connections** when done\n",
    "2. **Use parameterized queries** (never string formatting)\n",
    "3. **Commit after writes** (INSERT, UPDATE, DELETE)\n",
    "4. **Use transactions** for multiple related operations\n",
    "5. **Index frequently queried columns** (for performance)\n",
    "\n",
    "### Debugging Tips\n",
    "\n",
    "If something doesn't work:\n",
    "\n",
    "1. **Check the error message** â€” SQL errors are usually descriptive\n",
    "2. **Print your SQL** â€” Use `print(query)` to see what's being executed\n",
    "3. **Test queries in DB Browser** â€” Use a GUI tool to test SQL\n",
    "4. **Check data types** â€” Make sure your Python types match SQL types\n",
    "5. **Verify file paths** â€” Use absolute paths or check current directory\n",
    "\n",
    "### Common Errors\n",
    "\n",
    "| Error | Cause | Solution |\n",
    "|-------|-------|----------|\n",
    "| `table already exists` | Running CREATE TABLE twice | Use `IF NOT EXISTS` |\n",
    "| `UNIQUE constraint failed` | Duplicate username/ID | Check before INSERT |\n",
    "| `no such table` | Table not created | Run CREATE TABLE first |\n",
    "| `no such column` | Typo in column name | Check table schema |\n",
    "| `database is locked` | Connection not closed | Always close connections |\n",
    "\n",
    "---\n",
    "\n",
    "##  Additional Resources\n",
    "\n",
    "### SQLite Documentation\n",
    "- [SQLite Official Docs](https://www.sqlite.org/docs.html)\n",
    "- [Python sqlite3 Module](https://docs.python.org/3/library/sqlite3.html)\n",
    "\n",
    "### SQL Learning Resources\n",
    "- [W3Schools SQL Tutorial](https://www.w3schools.com/sql/)\n",
    "- [SQLite Tutorial](https://www.sqlitetutorial.net/)\n",
    "\n",
    "### Tools\n",
    "- [DB Browser for SQLite](https://sqlitebrowser.org/) â€” GUI for viewing/editing databases\n",
    "- [SQLite Viewer (VS Code Extension)](https://marketplace.visualstudio.com/items?itemName=alexcvzz.vscode-sqlite)\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
